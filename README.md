#### About 

# vicuna-finetune-deployment

This is the rep of detailed steps about the deployment of the vicuna model and its finetuning steps.

### Vicuna model  
https://github.com/thisserand/FastChat

### Post-Training Quantization for Generative Pre-trained Transformers (GPTQ) for LLaMA
https://github.com/oobabooga/GPTQ-for-LLaMa

[GPTQ](https://arxiv.org/abs/2210.17323) is SOTA one-shot weight quantization method.
